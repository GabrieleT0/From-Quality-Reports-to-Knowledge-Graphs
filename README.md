# From Quality Reports to Knowledge-Graphs
This repository contains code and data to reproduce the results presented in the article *"From Tables to Triples: A Prompt Engineering Approach"* submitted to [*PromptEng'25 - Workshop on Prompt Engineering for Pre-Trained Language Models@WebConf'25*](https://prompteng-ws.github.io/2025/).

The repository includes code and data to perform the conversion of a CSV file into a Knowledge Graph using Large Language Models (LLMs). The CSV used is the output generated by [KGHeartBeat](https://github.com/isislab-unisa/KGHeartbeat), containing the quality data of all Knowledge Graphs that can be automatically retrieved from DataHub and LODCloud.

The directory [experiments_results](./data/experiments_results/) contains .xlsx files with the results of the experiments, organized by the respective LLMs. The quality of the responses is reported for every five executions of the prompt, with results categorized by prompting methodology.

[LangChain](https://python.langchain.com/docs/introduction/) is used to execute the prompt on the LLM. Once the response is obtained, the [RDFLib library](https://rdflib.readthedocs.io/en/stable/) is utilized to parse the RDF graph and evaluate the quality of the generated response.

The approach has been tested on the following models:
- GPT-o1-mini (2024-09-12)
- GPT-4o (2024-08-06)
- Gemini 1.5 pro
- Claude 3.5 Sonnet

## How execute the CSV conversion ðŸš€
To run the code, it is necessary to have **Python version >= 3.13**.

1. It is recommended to create a virtual environment:

    ```sh
    python3 -m venv venv
    ```

2. Install the requirements:

    ```sh
    pip install -r requirements.txt
    ```

3. Create a .env file into the [src](./src/) directory that follows the structure of [env.example](./src/env.example):
    ```sh
    OPENAI_API_KEY = ""
    GOOGLE_AI = ""
    Claude = ""
    ```

4. Run the main to perform the conversion and perform the evaluation of the quality of the response. By launching the main without parameters, the test will be run on all the 3 LLMs, use the paramenters to select only some models
    ```sh
    python3 main.py # run the experiments on all the 3 LLMs tested

    python3 main.py -o # run the experiments on gpt-4o-2024-08-06 (by default is the model selected, you can change it by modifying the openAI_model variable in the main.py script)

    python3 main.py -g # run the experiments on Gemini 1.5 pro

    python3 main.py -c # run the experiments on Claude 3.5 Sonnet
    ```

   The LLMâ€™s response is saved in a .txt file named after the prompting method used and the model, e.g., zero_shot_acc_response_gemini.txt.

## Data used as input to the LLMs
The experiments results and data used as input to the LLM, along with the natural language message, are located in the [data](./data/) folder. The DQV is in the file [dqv.ttl](./data/dqv.ttl). 

The [quality_data](./data/quality_data/) directory contains the CSV file returned as output by KGHeartBeat and processed in such a way that they can be used as input to the LLM, helping to understand the structure, dimensions, and quality metrics.
- [only_accessibility.csv](./data/quality_data/only_accessibility.csv): contains KGs quality data related to the *Only Accessibility* use case.
- [full.csv](./data/quality_data/full.csv): contains KGs quality data related to the *All categories* use case.

The [full_examples](./data/full_examples/) directory contains the KG used as example to the LLM for the **one-shot prompting with full example** interaction.
- [cz-nace-accessibility.ttl](./data/full_examples/cz-nace-accessibility.ttl): is the KG used as example for the *Only Accessibility* use case.
- [cz-nace-full.ttl](./data/full_examples/cz-nace-full.ttl): is the KG used as example for the *All categories** use case.

 The [partial_solution_examples](./data/partial_solution_examples/) directory contains the KG used as example to the LLM for the **one-shot prompting with partial example** interaction.
 - [cz-nace-accessibility.ttl](./data/partial_solution_examples/cz-nace-accessibility.ttl): is the KG used as example for the *Only Accessibility* use case.
- [dbpediafr-partial.ttl](./data/partial_solution_examples/dbpediafr-partial.ttl): is the KG used as example for the *All categories** use case.

## Prompt used for the CSV conversion
In the [run_on_llms.py](./src/run_on_llms.py) file, there are the prompt templates used to task the LLM to execute the CSV conversion. The prompt used for the *prompt chaining* methodology and for the *hybrid prompting* are available in the [prompt_llms.py](./src/prompt_llms.py) file.