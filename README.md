# From Tables to Triples 
This repository contains code and data to reproduce the results presented in the article *"From Tables to Triples: A Prompt Engineering Approach"* submitted to [*PromptEng'25 - Workshop on Prompt Engineering for Pre-Trained Language Models@WebConf'25*](https://prompteng-ws.github.io/2025/).

The repository includes code and data to perform the conversion of a CSV file into a Knowledge Graph using Large Language Models (LLMs). The CSV used is the output generated by [KGHeartBeat](https://github.com/isislab-unisa/KGHeartbeat), containing the quality data of all Knowledge Graphs that can be automatically retrieved from DataHub and LODCloud.

[LangChain](https://python.langchain.com/docs/introduction/) is used to execute the prompt on the LLM. Once the response is obtained, the [RDFLib library](https://rdflib.readthedocs.io/en/stable/) is utilized to parse the RDF graph and evaluate the quality of the generated response.

The approach has been tested on the following models:
- GPT-o1-mini (2024-09-12)
- GPT-4o (2024-08-06)
- Gemini 1.5 pro
- Claude 3.5 Sonnet

## Run the code ðŸš€
To run the code, it is necessary to have **Python version >= 3.13**.

1. It is recommended to create a virtual environment:

    ```sh
    python3 -m venv venv
    ```

2. Install the requirements:

    ```sh
    pip install -r requirements.txt
    ```

3. Create a .env file into the [src](./src/) directory that follows the structure of [env.example](./src/env.example):
    ```sh
    OPENAI_API_KEY = ""
    GOOGLE_AI = ""
    Claude = ""
    ```

4. Modify the main.py file to select the model on which to execute the prompt. In main.py, the code is designed to run the test on Gemini 1.5 Pro ([see the following section to see how modify the main to execute on different LLMs](#how-modify-the-llms-used-in-the-mainpy-to-execute-the-conversion)):

    ```sh
    python3 main.py
    ```
   The LLMâ€™s response is saved in a .txt file named after the prompting method used and the model, e.g., zero_shot_acc_response_gemini.txt.

### How modify the LLMs used in the main.py to execute the conversion 
The only thing to modify for each executed prompt is the method called on the EvaluateKG object. Below is an example of how to change the zero-shot prompting from Gemini to GPT-4o:

#### Zero-shot prompting on Gemini
```py
    llms = PromptLLMS(zero_shot_prompt_only_acc,csv_title,csv_text,ttl_text)
    # Modify the following line of code
    gemini_response = llms.execute_on_gemini()
```

#### Zero-shot prompting on GPT-4o
```py
    llms = PromptLLMS(zero_shot_prompt_only_acc,csv_title,csv_text,ttl_text)
    # Prompting on GPT-4o
    openai_response = llms.execute_on_gpt_4(openAI_model)
```

## Data used as input to the LLMs
The data used as input to the LLM, along with the natural language message, are located in the [data](./data/) folder. The DQV is in the file [dqv.ttl](./data/dqv.ttl). 

The [quality_data](./data/quality_data/) directory contains the CSV file returned as output by KGHeartBeat and processed in such a way that they can be used as input to the LLM, helping to understand the structure, dimensions, and quality metrics.
- [only_accessibility.csv](./data/quality_data/only_accessibility.csv): contains KGs quality data related to the *Only Accessibility* use case.
- [full.csv](./data/quality_data/full.csv): contains KGs quality data related to the *All categories* use case.

The [full_examples](./data/full_examples/) directory contains the KG used as example to the LLM for the **one-shot prompting with full example** interaction.
- [cz-nace-accessibility.ttl](./data/full_examples/cz-nace-accessibility.ttl): is the KG used as example for the *Only Accessibility* use case.
- [cz-nace-full.ttl](./data/full_examples/cz-nace-full.ttl): is the KG used as example for the *All categories** use case.

 The [partial_solution_examples](./data/partial_solution_examples/) directory contains the KG used as example to the LLM for the **one-shot prompting with partial example** interaction.
 - [cz-nace-accessibility.ttl](./data/partial_solution_examples/cz-nace-accessibility.ttl): is the KG used as example for the *Only Accessibility* use case.
- [dbpediafr-partial.ttl](./data/partial_solution_examples/dbpediafr-partial.ttl): is the KG used as example for the *All categories** use case.